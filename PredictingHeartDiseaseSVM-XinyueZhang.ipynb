{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8c66d1c-9a78-4a9b-ac4a-3f3a1f2d8538",
   "metadata": {},
   "source": [
    "## Setting up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7284f3-a4ec-47c1-8931-786a8436279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00728f9-db02-4bc0-810c-bc99d0868952",
   "metadata": {},
   "source": [
    "## Model Summary Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b45a52-62a6-45d7-9d5a-331cd35f6323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelSummary Class\n",
    "class ModelSummary:\n",
    "    \"\"\"\n",
    "    This class extracts a summary of the model\n",
    "\n",
    "    Methods\n",
    "    ------\n",
    "    get_se()\n",
    "        Computes standard error\n",
    "    get_ci(SE_est)\n",
    "        Computes confidence intervals\n",
    "    get_pvals()\n",
    "        Computes p-values\n",
    "    get_summary(name=None)\n",
    "        Prints the summary of the model\n",
    "    \"\"\"\n",
    "    def __init__(self, clf, X, y):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ---------\n",
    "        clf: class\n",
    "            The classifier object model\n",
    "        X: pandas Dataframe\n",
    "            Matrix of predictors\n",
    "        y: numpy array\n",
    "            Matrix of variable\n",
    "        \"\"\"\n",
    "        self.clf = clf\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def get_se(self):\n",
    "        self.clf.predict_proba(self.X)\n",
    "        # From https://stats.stackexchange.com/questions/89484/how-to-compute-the-standard-errors-of-a-logistic-regressions-coefficient\n",
    "        predProbs = self.clf.predict_proba(self.X)\n",
    "        X_design = np.hstack([np.ones((self.X.shape[0], 1)), self.X])\n",
    "        V = np.diagflat(np.product(predProbs, axis=1))\n",
    "        covLogit = np.linalg.inv(np.dot(np.dot(X_design.T, V), X_design))\n",
    "        return np.sqrt(np.diag(covLogit))\n",
    "\n",
    "    def get_ci(self, SE_est):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ---------\n",
    "        SE_est: numpy array\n",
    "            Matrix of standard error estimations\n",
    "        \"\"\"\n",
    "        p = 0.975\n",
    "        df = len(self.X) - 2\n",
    "        crit_t_value = stats.t.ppf(p, df)\n",
    "        coefs = np.concatenate([self.clf.intercept_, self.clf.coef_[0]])\n",
    "        upper = coefs + (crit_t_value * SE_est)\n",
    "        lower = coefs - (crit_t_value * SE_est)\n",
    "        cis = np.zeros((len(coefs), 2))\n",
    "        cis[:, 0] = lower\n",
    "        cis[:, 1] = upper\n",
    "        return cis\n",
    "\n",
    "    def get_pvals(self):\n",
    "        self.clf.predict_proba(self.X)\n",
    "        # From https://stackoverflow.com/questions/25122999/scikit-learn-how-to-check-coefficients-significance\n",
    "        predProbs = self.clf.predict_proba(self.X)\n",
    "        n = len(predProbs)\n",
    "        m = len(self.clf.coef_[0]) + 1\n",
    "        se = self.get_se()\n",
    "        coefs = np.concatenate([self.clf.intercept_, self.clf.coef_[0]])\n",
    "        t = coefs / se\n",
    "        p = (1 - stats.norm.cdf(abs(t))) * 2\n",
    "        return p\n",
    "\n",
    "    def get_summary(self, names=None):\n",
    "        ses = self.get_se()\n",
    "        cis = self.get_ci(ses)\n",
    "        lower = cis[:, 0]\n",
    "        upper = cis[:, 1]\n",
    "        pvals = self.get_pvals()\n",
    "        coefs = np.concatenate([self.clf.intercept_, self.clf.coef_[0]])\n",
    "        data = []\n",
    "        for i in range(len(coefs)):\n",
    "            currlist = [np.round(coefs[i], 3), np.round(ses[i], 3), np.round(pvals[i], 3), np.round(lower[i], 3), np.round(upper[i], 3)]\n",
    "            data.append(currlist)\n",
    "        cols = ['coefficient', 'std', 'p-value', '[0.025', '0.975]']\n",
    "        sumdf = pd.DataFrame(columns=cols, data=data)\n",
    "        if names is not None:\n",
    "            new_names = ['intercept'] + names\n",
    "            sumdf.index = new_names\n",
    "        else:\n",
    "            try:\n",
    "                names = list(self.X.columns)\n",
    "                new_names = ['intercept'] + names\n",
    "                sumdf.index = new_names\n",
    "            except:\n",
    "                pass\n",
    "        print(sumdf)\n",
    "        acc = accuracy_score(self.y, self.clf.predict(self.X))\n",
    "        confmat = confusion_matrix(self.y, self.clf.predict(self.X))\n",
    "        print('-' * 60)\n",
    "        print('Confusion Matrix (total:{}) \\t Accuracy: \\t  {}'.format(len(self.X), np.round(acc, 3)))\n",
    "        print('  TP: {} | FN: {}'.format(confmat[1][1], confmat[1][0]))\n",
    "        print('  FP: {} | TN: {}'.format(confmat[0][1], confmat[0][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5538ae82-3b3d-4ffe-98f2-106c6e9ef098",
   "metadata": {},
   "source": [
    "## Importing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e4ad7a-ef1f-4387-8306-e2e7401cf290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# reading the datase\n",
    "data = pd.read_csv(\"heart_disease.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70387e94-6bd1-4a75-b798-32ebb3474500",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb6918-fa5d-41d8-840c-0af59b6483fa",
   "metadata": {},
   "source": [
    "### Binarising dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9d8de-0271-40e4-8c87-8ace8b37d765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarising Dataset\n",
    "# Identify categorical features\n",
    "categorical_features = ['cp', 'restecg', 'slope', 'thal']\n",
    "# Perform one-hot encoding and drop the first category for features with more than 2 categories\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_features, drop_first=True)\n",
    "data_encoded = data_encoded.drop('cp_typical angina', axis=1)\n",
    "#Binarising to 0 and 1\n",
    "data_encoded = data_encoded.replace({True: 1, False: 0})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a07fcd2-a6f1-4ae6-8ccd-66a3c30b677a",
   "metadata": {},
   "source": [
    "### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259a60c3-f5fa-483e-9a8a-2117bafb10d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "correlation_matrix = data_encoded.corr()\n",
    "# Print the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519ea302-d9a1-4e27-8e69-2699822c3ee7",
   "metadata": {},
   "source": [
    "### Removing unwanted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e47ebb3-6cdb-44f2-b5a5-4a0f0e054c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing features unwanted after feature engineering\n",
    "data_encoded=data_encoded.drop(['trestbps','chol','fbs','restecg_st-t  abnormality','slope_upsloping','thal_reversable defect'], axis=1)\n",
    "data_encoded.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ace4de1-9f3d-4a0e-a095-9a9075405418",
   "metadata": {},
   "source": [
    "### Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac47bb2-16cc-4a79-b699-cbaf1c83b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the independent and dependent variables\n",
    "X = data_encoded.drop('num', axis = 1)\n",
    "y = data_encoded['num']\n",
    "\n",
    "# generating confusion matrix\n",
    "mod = LogisticRegression()\n",
    "mod.fit(X, y)\n",
    "modsummary = ModelSummary(mod, X, y)\n",
    "modsummary.get_summary()\n",
    "total = len(data_encoded)\n",
    "\n",
    "#positive and negative dataset\n",
    "total = len(data_encoded)\n",
    "pos = data_encoded['num'].sum() \n",
    "neg = total - pos \n",
    "\n",
    "# splitting by 70%, 30%\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=0)\n",
    "\n",
    "# splitting by 70%, 15%, 15%\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5, random_state=0)\n",
    "print('The sizes for train, validation, test should be {}'.format((len(X_train), len(X_val), len(X_test))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70f094b-e849-4ac9-b21e-01e010a9bcff",
   "metadata": {},
   "source": [
    "### Standandardising dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d94d8ae-80d7-43e1-9541-e461b89629b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the datasets\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e8515d-b993-4929-9dbc-329c17f2ae3e",
   "metadata": {},
   "source": [
    "## Testing different kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02451c4-5148-4d9a-91e2-0a3a537cee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default SVM model\n",
    "model = SVC(probability=True, C=1, kernel='linear', gamma='scale')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Model comparison with different kernels\n",
    "## accuracy\n",
    "accuracytrain = []\n",
    "accuracyval = []\n",
    "for k in ('linear', 'poly', 'rbf', 'sigmoid'):\n",
    "    model = SVC(kernel=k, C = 1, gamma='scale')\n",
    "    model.fit(X_train, y_train)\n",
    "    print(k)\n",
    "    y_predtrain = model.predict(X_train)\n",
    "    accuracytrain.append(accuracy_score(y_train, y_predtrain))\n",
    "    y_predval = model.predict(X_val)\n",
    "    accuracyval.append(accuracy_score(y_val, y_predval))\n",
    "\n",
    "kernelyaxis = ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "plt.plot(kernelyaxis, accuracytrain, 'g', label = 'Training')\n",
    "plt.plot(kernelyaxis, accuracyval, 'b', label = 'Validation')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Kernel')\n",
    "plt.title('Accuracy Scores of Training Set (green) and Validation Set (blue) (C=1, gamma = scale)')\n",
    "\n",
    "\n",
    "## precision\n",
    "precisiontrain = []\n",
    "precisionval = []\n",
    "for k in ('linear', 'poly', 'rbf', 'sigmoid'):\n",
    "    model = SVC(kernel=k, C = 1, gamma='scale')\n",
    "    model.fit(X_train, y_train)\n",
    "    print(k)\n",
    "    y_predtrain = model.predict(X_train)\n",
    "    precisiontrain.append(precision_score(y_train, y_predtrain))\n",
    "    y_predval = model.predict(X_val)\n",
    "    precisionval.append(precision_score(y_val, y_predval))\n",
    "\n",
    "kernelyaxis = ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "plt.plot(kernelyaxis, precisiontrain, 'g', label = 'Training')\n",
    "plt.plot(kernelyaxis, precisionval, 'b', label = 'Validation')\n",
    "plt.xlabel('Precision')\n",
    "plt.ylabel('Kernel')\n",
    "plt.title('Precision Scores of Training Set (green) and Validation Set (blue) (C=1, gamma = scale)')\n",
    "\n",
    "## recall\n",
    "recalltrain = []\n",
    "recallval = []\n",
    "for k in ('linear', 'poly', 'rbf', 'sigmoid'):\n",
    "    model = SVC(kernel=k, C = 1, gamma='scale')\n",
    "    model.fit(X_train, y_train)\n",
    "    print(k)\n",
    "    y_predtrain = model.predict(X_train)\n",
    "    recalltrain.append(recall_score(y_train, y_predtrain))\n",
    "    y_predval = model.predict(X_val)\n",
    "    recallval.append(recall_score(y_val, y_predval))\n",
    "\n",
    "kernelyaxis = ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "plt.plot(kernelyaxis, recalltrain, 'g', label = 'Training')\n",
    "plt.plot(kernelyaxis, recallval, 'b', label = 'Validation')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Kernel')\n",
    "plt.title('Recall Scores of Training Set (green) and Validation Set (blue) (C=1, gamma = scale)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f8269f-56b4-4764-8991-c8d41d353f60",
   "metadata": {},
   "source": [
    "## Testing varying C-Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c67e2-79a0-423f-935e-bd12c03809a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing varying C\n",
    "accuracy_train_c = []\n",
    "accuracy_val_c = []\n",
    "precision_train_c = []\n",
    "precision_val_c = []\n",
    "recall_train_c = []\n",
    "recall_val_c = []\n",
    "y_data_c = []\n",
    "for c in np.arange(0.1, 10, 0.05):\n",
    "    y_data_c.append(c)\n",
    "    model = SVC(kernel='poly', C=c, gamma = 'scale')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predtrain = model.predict(X_train)\n",
    "    accuracy_train_c.append(accuracy_score(y_train, y_predtrain))\n",
    "    recall_train_c.append(recall_score(y_train, y_predtrain))\n",
    "    precision_train_c.append(precision_score(y_train, y_predtrain))\n",
    "    y_predval = model.predict(X_val)\n",
    "    accuracy_val_c.append(accuracy_score(y_val, y_predval))\n",
    "    recall_val_c.append(recall_score(y_val, y_predval))\n",
    "    precision_val_c.append(precision_score(y_val, y_predval))\n",
    "\n",
    "plt.plot(y_data_c, accuracy_train_c, 'g', label='Training Set')\n",
    "plt.plot(y_data_c, accuracy_val_c, 'b', label='Validation Set')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('C')\n",
    "plt.title('Accuracy Scores of Training Set and Validation Set, varying C')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(y_data_c, precision_train_c, 'g', label='Training Set')\n",
    "plt.plot(y_data_c, precision_val_c, 'b', label='Validation Set')\n",
    "plt.ylabel('Prediction')\n",
    "plt.xlabel('C')\n",
    "plt.title('Precision Scores of Training Set and Validation Set, varying C')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(y_data_c, recall_train_c, 'g', label='Training Set')\n",
    "plt.plot(y_data_c, recall_val_c, 'b', label='Validation Set')\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('C')\n",
    "plt.title('Recall Scores of Training Set and Validation Set, varying C')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63faeea4-9e40-4eb2-a80a-91a3d23b4aef",
   "metadata": {},
   "source": [
    "## Testing varying gamma value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7241799-52dc-476b-a018-7bc736840306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with varying gamma\n",
    "accuracy_train_g = []\n",
    "accuracy_val_g = []\n",
    "precision_train_g = []\n",
    "precision_val_g = []\n",
    "recall_train_g = []\n",
    "recall_val_g = []\n",
    "y_data_g = []\n",
    "\n",
    "for g in np.arange(0.001, 0.1, 0.001):\n",
    "    y_data_g.append(g)\n",
    "    model = SVC(kernel='poly', C=2, gamma = g)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predtrain = model.predict(X_train)\n",
    "    accuracy_train_g.append(accuracy_score(y_train, y_predtrain))\n",
    "    recall_train_g.append(recall_score(y_train, y_predtrain))\n",
    "    precision_train_g.append(precision_score(y_train, y_predtrain))\n",
    "    y_predval = model.predict(X_val)\n",
    "    accuracy_val_g.append(accuracy_score(y_val, y_predval))\n",
    "    recall_val_g.append(recall_score(y_val, y_predval))\n",
    "    precision_val_g.append(precision_score(y_val, y_predval))\n",
    "\n",
    "plt.plot(y_data_g, accuracy_train_g, 'g', label='Training Set')\n",
    "plt.plot(y_data_g, accuracy_val_g, 'b', label='Validation Set')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('gamma')\n",
    "plt.title('Accuracy Scores of Training Set and Validation Set, varying gamma')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(y_data_g, precision_train_g, 'g', label='Training Set')\n",
    "plt.plot(y_data_g, precision_val_g, 'b', label='Validation Set')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('gamma')\n",
    "plt.title('Precision Scores of Training Set and Validation Set, varying gamma')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(y_data_g, recall_train_g, 'g', label='Training Set')\n",
    "plt.plot(y_data_g, recall_val_g, 'b', label='Validation Set')\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('gamma')\n",
    "plt.title('Recall Scores of Training Set and Validation Set, varying gamma')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f48bb-1af8-4f66-bb79-482183153d51",
   "metadata": {},
   "source": [
    "## Fianl model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc410be-1957-43d3-bf42-f65f47cacb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model with best  value\n",
    "model2 = SVC(probability=True, kernel='poly', C=2,  gamma = 0.05)\n",
    "model2.fit(X_train, y_train)\n",
    "y_predtr = model2.predict(X_train)\n",
    "accuracytr = accuracy_score(y_train, y_predtr)\n",
    "precisiontr = precision_score(y_train, y_predtr)\n",
    "recalltr = recall_score(y_train, y_predtr)\n",
    "print(f\"training accuracy: {accuracytr}, training precision: {precisiontr}, training recall: {recalltr}\")\n",
    "\n",
    "y_pred = model2.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred)\n",
    "recall = recall_score(y_val, y_pred)\n",
    "print(f\"validation accuracy: {accuracy}, validation precision: {precision}, validation recall: {recall}\")\n",
    "\n",
    "y_predt = model2.predict(X_test)\n",
    "accuracyt = accuracy_score(y_test, y_predt)\n",
    "precisiont = precision_score(y_test, y_predt)\n",
    "recallt = recall_score(y_test, y_predt)\n",
    "print(f\" test accuracy: {accuracyt}, test precision: {precisiont}, test recall: {recallt}\")\n",
    "\n",
    "# Confusion matrix for test set\n",
    "cm = confusion_matrix(y_test, y_predt)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap='Blues',annot=True)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Reality')\n",
    "ax.set_title('Confusion Matrix(Test)')\n",
    "ax.xaxis.set_ticklabels(['Negative', 'Positive'])\n",
    "ax.yaxis.set_ticklabels(['Negative', 'Positive'])\n",
    "plt.show()\n",
    "\n",
    "recall = recall_score(y_test, y_predt)\n",
    "print(f\"recall: {recall}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5723efc-e572-4349-8e7d-df3028288105",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c29044-2238-4ccb-92e0-9d1e6d9b0b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Rank the importance of the features with PCA\n",
    "components = pca.components_\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "feature_importance = np.abs(components) * explained_variance.reshape(-1, 1)\n",
    "feature_importance = feature_importance.sum(axis=0)\n",
    "feature_ranking = np.argsort(feature_importance)[::-1]\n",
    "# Print feature rankings\n",
    "print(\"Feature ranking (most important first):\")\n",
    "for rank, index in enumerate(feature_ranking):\n",
    "    print(f\"Rank {rank + 1}: Feature {index} (importance = {feature_importance[index]:.4f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda0d7b9-b0fa-4052-9ef3-e28f93fbb7a6",
   "metadata": {},
   "source": [
    "## Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf1263-ba1d-40ee-a59b-02a7b726621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "\n",
    "heart = pd.read_csv('heart_disease_uci_2.csv')\n",
    "\n",
    "# categorical variable into a binary \n",
    "# cp\n",
    "heart['cp atypical angina'] = heart['cp'] == 'atypical angina'\n",
    "heart['cp atypical angina'] = heart['cp atypical angina'].astype(int)\n",
    "\n",
    "heart['cp non-anginal'] = heart['cp'] == 'non-anginal'\n",
    "heart['cp non-anginal'] = heart['cp non-anginal'].astype(int)\n",
    "\n",
    "heart['cp typical angina'] = heart['cp'] == 'typical angina'\n",
    "heart['cp typical angina'] = heart['cp typical angina'].astype(int)\n",
    "\n",
    "# restecg\n",
    "heart['restecg normal'] = heart['restecg'] == 'normal'\n",
    "heart['restecg normal'] = heart['restecg normal'].astype(int)\n",
    "\n",
    "heart['restecg st-t abnormality'] = heart['restecg'] == 'st-t abnormality'\n",
    "heart['restecg st-t abnormality'] = heart['restecg st-t abnormality'].astype(int)\n",
    "\n",
    "# slope\n",
    "heart['slope flat'] = heart['slope'] == 'flat'\n",
    "heart['slope flat'] = heart['slope flat'].astype(int)\n",
    "\n",
    "heart['slope upsloping'] = heart['slope'] == 'upsloping'\n",
    "heart['slope upsloping'] = heart['slope upsloping'].astype(int)\n",
    "\n",
    "# thal\n",
    "heart['thal normal'] = heart['thal'] == 'normal'\n",
    "heart['thal normal'] = heart['thal normal'].astype(int)\n",
    "heart['thal reversable defect'] = heart['thal'] == 'reversable defect'\n",
    "heart['thal reversable defect'] = heart['thal reversable defect'].astype(int)\n",
    "\n",
    "del heart['cp']\n",
    "del heart['restecg']\n",
    "del heart['thal']\n",
    "del heart['slope']\n",
    "\n",
    "heart.head()\n",
    "\n",
    "# plotting correlation heatmap \n",
    "dataplot = sb.heatmap(heart.corr())\n",
    "# displaying heatmap \n",
    "plt.show()\n",
    "\n",
    "plt.savefig('heatmap.png', dpi=300)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
